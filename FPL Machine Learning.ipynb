{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from source.classes import FPL_data\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import r_regression, f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5bc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = FPL_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SVC classifier\n",
    "# test different SVC kernels\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "for k in ['rbf', 'linear', 'poly']: #, 'sigmoid']:\n",
    "    gg.build_svc(type_scaler = 'range', kernel_type = k, feature_selection = None)\n",
    "    print('SVC ', k)\n",
    "    gg.predict('svc')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['encoded'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['svc'], color = 'r')\n",
    "    axes[y].set_title(f'SVC - {k}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test KNN classifier\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, sharey=True)\n",
    "y = 0\n",
    "\n",
    "for w, n in itertools.product(['uniform','distance'], [5, 10, 15, 20]):\n",
    "    gg.build_knn_clf(type_scaler = 'range', weights = w, n_neighbors = n)\n",
    "    print('KNN_CLF', w, n)\n",
    "    gg.predict('knn_clf')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['encoded'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['knn_clf'], color = 'r')\n",
    "    axes[y].set_title(f'KNN CLF - {w}, {n}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da52449",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.build_knn_clf(type_scaler = 'range', weights = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a018f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different decision trees classifier\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "for c in ['gini', 'log_loss', 'entropy']:\n",
    "    gg.build_dtc(type_scaler = 'range', criterion = c)\n",
    "    print('DTC', c)\n",
    "    gg.predict('dtc')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['encoded'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['dtc'], color = 'r')\n",
    "    axes[y].set_title(f'DTC - {c}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different mlp - classifier\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "for fs in [r_regression, f_regression, mutual_info_regression]:\n",
    "    gg.build_mlp_clf(type_scaler = 'range', feature_selection = fs)\n",
    "    print('MLP - CLF', fs)\n",
    "    gg.predict('mlp_clf')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['encoded'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['mlp_clf'], color = 'r')\n",
    "    axes[y].set_title(f'MLP-CLF - {fs}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "plt.scatter(xx, gg.data_dict['y_test']['encoded'])\n",
    "plt.scatter(xx,gg.data_dict['y_predicted']['svc'], color = 'r', marker = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different K Neighbors\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, sharey=True)\n",
    "y = 0\n",
    "\n",
    "for w, n in itertools.product(['uniform','distance'], [5, 10, 15, 20]):\n",
    "    gg.build_knn(type_scaler = 'range', weights = w)\n",
    "    print('KNN', w, n)\n",
    "    gg.predict('knn')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['knn'], color = 'r')\n",
    "    axes[y].set_title(f'KNN - {w}, {n}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aea3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.knn_regression.score(gg.data_dict['X_test']['reduced'], gg.data_dict['y_test']['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different SVR kernels\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "for k in ['rbf', 'linear', 'poly']: #, 'sigmoid']:\n",
    "    gg.build_svr(type_scaler = 'range', kernel_type = k, feature_selection = r_regression)\n",
    "    print('SVR ', k)\n",
    "    gg.predict('svr')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['svr'], color = 'r')\n",
    "    axes[y].set_title(f'SVR - {k}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bbbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different SVR kernels\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "for k in ['rbf', 'linear', 'poly']: #, 'sigmoid']:\n",
    "    gg.build_svr(type_scaler = 'range', kernel_type = k, feature_selection = r_regression)\n",
    "    print('SVR ', k)\n",
    "    gg.predict('svr')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['svr'], color = 'r')\n",
    "    axes[y].set_title(f'SVR - {k}')\n",
    "    y += 1\n",
    "    \n",
    "    \n",
    "# test different K Neighbors\n",
    "for w, n in itertools.product(['uniform','distance'], [10]):\n",
    "    gg.build_knn(type_scaler = 'range', weights = w)\n",
    "    print('KNN', w, n)\n",
    "    gg.predict('knn')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['knn'], color = 'r')\n",
    "    axes[y].set_title(f'KNN - {w}, {n}')\n",
    "    y += 1\n",
    "    \n",
    "# test different decision trees\n",
    "for c in ['squared_error', 'friedman_mse', 'absolute_error']:\n",
    "    gg.build_dtr(type_scaler = 'range', criterion = c)\n",
    "    print('DTR', c)\n",
    "    gg.predict('dtr')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['dtr'], color = 'r')\n",
    "    axes[y].set_title(f'DTR - {c}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc194315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different decision trees\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "for c in ['squared_error', 'friedman_mse', 'absolute_error']:\n",
    "    gg.build_dtr(type_scaler = 'range', criterion = c)\n",
    "    print('DTR', c)\n",
    "    gg.predict('dtr')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['dtr'], color = 'r')\n",
    "    axes[y].set_title(f'DTR - {c}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different mlp\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "x = 0\n",
    "y = 0\n",
    "for fs in [r_regression, f_regression, mutual_info_regression]:\n",
    "    gg.build_mlp(type_scaler = 'range', feature_selection = fs)\n",
    "    print('MLP', fs)\n",
    "    gg.predict('mlp')\n",
    "    xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "    axes[y].scatter(xx, gg.data_dict['y_predicted']['mlp'], color = 'r')\n",
    "    axes[y].set_title(f'MLP - {fs}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a388929",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = range(1,len(gg.data_dict['y_test']['raw'])+1)\n",
    "plt.scatter(xx, gg.data_dict['y_test']['raw'])\n",
    "plt.scatter(xx, gg.data_dict['y_predicted']['dtr'], color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6123321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ML_analysis import prepare_model_input\n",
    "\n",
    "# add position to input data\n",
    "gg.input_data['position'] = [gg.player_dict[i]['element_type'] for i in gg.input_data['element']]\n",
    "\n",
    "gg.forwards = gg.input_data[gg.input_data['position'] == 4].reset_index(drop = True)\n",
    "gg.forward_ML = prepare_model_input(gg.forwards)\n",
    "\n",
    "gg.keepers = gg.input_data[gg.input_data['position'] == 1].reset_index(drop = True)\n",
    "gg.keeper_ML = prepare_model_input(gg.keepers)\n",
    "\n",
    "gg.defenders = gg.input_data[gg.input_data['position'] == 2].reset_index(drop = True)\n",
    "gg.defender_ML = prepare_model_input(gg.defenders)\n",
    "\n",
    "gg.mids = gg.input_data[gg.input_data['position'] == 3].reset_index(drop = True)\n",
    "gg.mid_ML = prepare_model_input(gg.mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ML_analysis import build_mlp\n",
    "# build_mlp(input_df, predicted_value = 'total_points', scaler_type = 'standard', max_iter = 500, feature_selection = r_regression)\n",
    "# outputs = regr, scaler, feature_selector, d_type, data\n",
    "# test different mlp - with forwards only\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, sharey=True)\n",
    "y = 0\n",
    "for pos in [gg.keeper_ML, gg.defender_ML, gg.mid_ML, gg.forward_ML]:\n",
    "    regr, scaler, feature_selector, d_type, data = build_mlp(pos, max_iter = 1000, scaler_type = 'range', feature_selection = f_regression)\n",
    "    print(regr.score(data['X_test'][d_type], data['y_test']['raw']))\n",
    "    y_pred = regr.predict(data['X_test'][d_type])\n",
    "    xx = range(1,len(data['y_test']['raw'])+1)\n",
    "    axes[y].scatter(xx, data['y_test']['raw'])\n",
    "    axes[y].scatter(xx, y_pred, color = 'r')\n",
    "    #axes[y].set_title(f'MLP - {fs}')\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a82d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.score(data['X_test'][d_type], data['y_test']['raw'])\n",
    "y_pred = regr.predict(data['X_test'][d_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e059e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = range(1,len(data['y_test']['raw'])+1)\n",
    "plt.scatter(xx, data['y_test']['raw'])\n",
    "plt.scatter(xx, y_pred, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler = preprocessing.MinMaxScaler()\n",
    "y_scaler.fit(gg.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import r_regression, f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(6.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0723904",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(6.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94569a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
